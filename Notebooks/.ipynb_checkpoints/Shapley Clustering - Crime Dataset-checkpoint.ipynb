{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d03a94bde3ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shap\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.30.0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKernelExplainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSamplingExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTreeExplainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shap\\explainers\\kernel.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvert_to_instance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_to_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch_instance_to_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch_model_to_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_to_instance_with_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_to_link\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIdentityLink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_to_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDenseData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparseData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbinom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\shap\\common.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mkdtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mckdtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mqhull\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\kdtree.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mheapq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mheappush\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheappop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m __all__ = ['minkowski_distance_p', 'minkowski_distance',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdok\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\lil.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                       \u001b[0mupcast_scalar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misintlike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                       check_reshape_kwargs)\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_csparsetools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import shap\n",
    "import xgboost\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import colorsys\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train XGBoost model\n",
    "X,y = shap.datasets.communitiesandcrime()\n",
    "X = X.reset_index()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X, label=y), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_instanced = pd.concat((X,pd.DataFrame(columns = ['instance'])),axis = 1)\n",
    "X_instanced['instance'].loc[X_train.index] = 'train'\n",
    "X_instanced['instance'].loc[X_test.index] = 'test'\n",
    "y_instanced = pd.concat((pd.DataFrame(y),pd.DataFrame(columns = ['instance'])),axis = 1)\n",
    "y_instanced['instance'].loc[X_train.index] = 'train'\n",
    "y_instanced['instance'].loc[X_test.index] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP values\n",
    "# (same syntax works for LightGBM, CatBoost, and scikit-learn models)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "#shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the training set predictions\n",
    "#shap.force_plot(explainer.expected_value, shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "#shap.summary_plot(shap_values, X,plot_type = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "#shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather shapley values and output values in one dataframe\n",
    "shap_dataframe = pd.DataFrame(data = shap_values,columns = X.columns)\n",
    "output_dataframe = pd.DataFrame(data = y,columns = ['crimes'])\n",
    "shap_dataframe = pd.concat([shap_dataframe,output_dataframe],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make interaction plot for all features\n",
    "#shap_interaction_values = explainer.shap_interaction_values(X)\n",
    "#shap.summary_plot(shap_interaction_values, X, max_display = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Framework import plotHelper\n",
    "#plotHelper.plotAllFeatures(shap_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start clustering\n",
    "from Framework import cluster\n",
    "from sklearn.cluster import KMeans\n",
    "nClusters = 3\n",
    "#Train KMeans, because the data is unsupervised(Regression data)\n",
    "#kmeans = KMeans(n_clusters=3, random_state=0).fit(shap_values)\n",
    "kmeans = cluster.clusterData(KMeans(n_clusters=nClusters, random_state=0).fit,shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the labels, concat into original data, and sor the labels for into cluster groups\n",
    "shap_dataframe_labeled = pd.concat([shap_dataframe,pd.DataFrame(kmeans.labels_,columns =[ 'labels'])],axis = 1)\n",
    "#shap_grouped = shap_dataframe_labeled.sort_values(['labels'])\n",
    "X_labeled = pd.concat([X,shap_dataframe_labeled['labels']], axis = 1)\n",
    "plt.scatter(np.linspace(0,len(X),len(X)),y,c = X_labeled['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_original = cluster.clusterData(KMeans(n_clusters=nClusters, random_state=0).fit,X)\n",
    "plt.scatter(np.arange(len(X)),y,c = kmeans_original.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the clusters into a dictionary\n",
    "data_dict = cluster.splitDataLabeled(nClusters,shap_dataframe,shap_dataframe_labeled['labels'])\n",
    "data_dict_original = cluster.splitDataLabeled(nClusters,X,kmeans_original.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_split = cluster.convertOriginalData(data_dict_original,X_instanced,y_instanced)\n",
    "original_split_shapley = cluster.convertOriginalData(data_dict,X_instanced,y_instanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter the groups again...\n",
    "#plt.scatter(np.linspace(-1,1,len(original_label_cluster2)),cluster2_predictions)\n",
    "plt.scatter(np.arange(len(original_split['original_label_cluster0'])),original_split['original_label_cluster0'].iloc[:,0])\n",
    "plt.scatter(np.arange(len(original_split['original_label_cluster1'])),original_split['original_label_cluster1'].iloc[:,0])\n",
    "plt.scatter(np.arange(len(original_split['original_label_cluster2'])),original_split['original_label_cluster2'].iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(original_split_shapley['original_label_cluster0'])),original_split_shapley['original_label_cluster0'].iloc[:,0])\n",
    "plt.scatter(np.arange(len(original_split_shapley['original_label_cluster1'])),original_split_shapley['original_label_cluster1'].iloc[:,0])\n",
    "plt.scatter(np.arange(len(original_split_shapley['original_label_cluster2'])),original_split_shapley['original_label_cluster2'].iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train split XGBoost models over original data\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 1,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y),\n",
    "    \"eval_metric\": \"rmse\"\n",
    "}\n",
    "\n",
    "eval_results = {}\n",
    "kwargs = {\n",
    "    'num_boost_round':10000,\n",
    "    'verbose_eval': 1000,\n",
    "    'evals_result' : {},\n",
    "    'early_stopping_rounds' : 200\n",
    "}\n",
    "\n",
    "model_dict,eval_results = cluster.trainMultipleModels(xgboost.train,original_split,'XGBoost',params,**kwargs)\n",
    "#small_model_1 = xgboost.train(params,xgboost.DMatrix(original_split['original_data_cluster0'], label=original_split['original_label_cluster0']),20000,evals = [(xgboost.DMatrix(original_split['original_data_cluster0'], label=original_split['original_label_cluster0']), \"train\")] ,verbose_eval = 1000)\n",
    "#small_model_2 = xgboost.train(params,xgboost.DMatrix(original_split['original_data_cluster1'], label=original_split['original_label_cluster1']),20000,evals = [(xgboost.DMatrix(original_split['original_data_cluster1'], label=original_split['original_label_cluster1']), \"train\")] ,verbose_eval = 1000)\n",
    "#small_model_3 = xgboost.train(params,xgboost.DMatrix(original_split['original_data_cluster2'], label=original_split['original_label_cluster2']),20000,evals = [(xgboost.DMatrix(original_split['original_data_cluster2'], label=original_split['original_label_cluster2']), \"train\")] ,verbose_eval = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train split XGBoost models over original data\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 1,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y),\n",
    "    \"eval_metric\": \"rmse\"\n",
    "}\n",
    "eval_results_shapley = {}\n",
    "kwargs = {\n",
    "    'num_boost_round':10000,\n",
    "    'verbose_eval': 1000,\n",
    "    'evals_result' : {},\n",
    "    'early_stopping_rounds' : 200\n",
    "}\n",
    "model_dict_shapley,eval_results_shapley = cluster.trainMultipleModels(xgboost.train,original_split_shapley,'XGBoost',params,**kwargs)\n",
    "#small_model_shapley1 = xgboost.train(params,xgboost.DMatrix(original_split_shapley['original_data_cluster0'], label=original_split_shapley['original_label_cluster0']),20000,evals = [(xgboost.DMatrix(original_split_shapley['original_data_cluster0'], label=original_split_shapley['original_label_cluster0']), \"train\")] ,verbose_eval = 1000)\n",
    "#small_model_shapley2 = xgboost.train(params,xgboost.DMatrix(original_split_shapley['original_data_cluster1'], label=original_split_shapley['original_label_cluster1']),20000,evals = [(xgboost.DMatrix(original_split_shapley['original_data_cluster1'], label=original_split_shapley['original_label_cluster1']), \"train\")] ,verbose_eval = 1000)\n",
    "#small_model_shapley3 = xgboost.train(params,xgboost.DMatrix(original_split_shapley['original_data_cluster2'], label=original_split_shapley['original_label_cluster2']),20000,evals = [(xgboost.DMatrix(original_split_shapley['original_data_cluster2'], label=original_split_shapley['original_label_cluster2']), \"train\")] ,verbose_eval = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(eval_results['eval0']['test']['rmse'])),eval_results['eval0']['test']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results['eval1']['test']['rmse'])),eval_results['eval1']['test']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results['eval2']['test']['rmse'])),eval_results['eval2']['test']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shapley['eval0']['test']['rmse'])),eval_results_shapley['eval0']['test']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shapley['eval1']['test']['rmse'])),eval_results_shapley['eval1']['test']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shapley['eval2']['test']['rmse'])),eval_results_shapley['eval2']['test']['rmse'])\n",
    "plt.xlabel('Epoch count')\n",
    "plt.ylabel('Test-RMSE')\n",
    "plt.legend(['Model0','Model1','Model2','Model0_Shapley','Model1_Shapley','Model2_Shapley'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(eval_results['eval0']['train']['rmse'])),eval_results['eval0']['train']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results['eval1']['train']['rmse'])),eval_results['eval1']['train']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results['eval2']['train']['rmse'])),eval_results['eval2']['train']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shapley['eval0']['train']['rmse'])),eval_results_shapley['eval0']['train']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shapley['eval1']['train']['rmse'])),eval_results_shapley['eval1']['train']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shapley['eval2']['train']['rmse'])),eval_results_shapley['eval2']['train']['rmse'])\n",
    "plt.xlabel('Epoch count')\n",
    "plt.ylabel('Train-RMSE')\n",
    "plt.legend(['Model0','Model1','Model2','Model0_Shapley','Model1_Shapley','Model2_Shapley'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds =model.predict(xgboost.DMatrix(original_split['original_data_cluster0']))\n",
    "plt.scatter(np.arange(len(original_split['original_test_label_cluster0'])),original_split['original_test_label_cluster0'])\n",
    "plt.scatter(np.arange(len(original_split['original_test_label_cluster0'])),model_dict['model0'].predict(xgboost.DMatrix(original_split['original_test_cluster0'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds =model.predict(xgboost.DMatrix(original_split['original_data_cluster0']))\n",
    "plt.scatter(np.arange(len(original_split_shapley['original_test_label_cluster0'])),original_split_shapley['original_test_label_cluster0'])\n",
    "plt.scatter(np.arange(len(original_split_shapley['original_test_label_cluster0'])),model_dict_shapley['model0'].predict(xgboost.DMatrix(original_split_shapley['original_test_cluster0'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train overall model\n",
    "ev_result = {}\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 1,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y),\n",
    "    \"eval_metric\": \"rmse\",\n",
    "}\n",
    "model = xgboost.train(params,xgboost.DMatrix(X_train, label=y_train),10000,evals = [(xgboost.DMatrix(X_train, label=y_train), \"train\"),(xgboost.DMatrix(X_test, label=y_test), \"test\")] ,verbose_eval = 1000,evals_result = ev_result,early_stopping_rounds = 200)\n",
    "tot_result_big_model = min(ev_result['test']['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(ev_result['test']['rmse'])),ev_result['test']['rmse'])\n",
    "plt.xlabel('Epoch count')\n",
    "plt.ylabel('Test-RMSE')\n",
    "plt.legend(['General Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(ev_result['train']['rmse'])),ev_result['train']['rmse'])\n",
    "plt.xlabel('Epoch count')\n",
    "plt.ylabel('Train-RMSE')\n",
    "plt.legend(['General Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(X_test)),y_test)\n",
    "plt.scatter(np.arange(len(X_test)),model.predict(xgboost.DMatrix(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of results\n",
    "from Framework import metrics\n",
    "sizes = []\n",
    "rmse_array = []\n",
    "for i in range(nClusters):\n",
    "    sizes.append(len(original_split['original_test_label_cluster{0}'.format(i)]))\n",
    "    rmse_array.append(min(eval_results['eval{0}'.format(i)]['test']['rmse']))\n",
    "tot_rmse_org = metrics.ensembleRMSE(sizes,rmse_array)\n",
    "\n",
    "sizes = []\n",
    "rmse_array = []\n",
    "for i in range(nClusters):\n",
    "    sizes.append(len(original_split_shapley['original_test_label_cluster{0}'.format(i)]))\n",
    "    rmse_array.append(min(eval_results_shapley['eval{0}'.format(i)]['test']['rmse']))\n",
    "tot_rmse_shap = metrics.ensembleRMSE(sizes,rmse_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do PCA for dimensionality reduction\n",
    "nPcaComponents = 2\n",
    "pca = PCA(n_components=nPcaComponents)\n",
    "shap_values_pca = pca.fit_transform(shap_values)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do PCA for dimensionality reduction\n",
    "nPcaComponents = 2\n",
    "pca_org = PCA(n_components=nPcaComponents)\n",
    "org_values_pca = pca_org.fit_transform(X)\n",
    "print(pca_org.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Clusters are quite seperate,could be used in clustering\n",
    "label_colors = [ 0 if a == 'train' else 1 for a in X_instanced['instance']]\n",
    "plt.scatter(shap_values_pca[:,0],shap_values_pca[:,1], c = label_colors)\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "#Add to labels to the scatter plot (Colors)\n",
    "#How do we interpret this ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pca = cluster.clusterData(KMeans(n_clusters=nPcaComponents, random_state=0).fit,shap_values_pca)\n",
    "kmeans_org_pca = cluster.clusterData(KMeans(n_clusters=nPcaComponents, random_state=0).fit,org_values_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(shap_values_pca[:,0],shap_values_pca[:,1], c = kmeans_pca.labels_)\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_shap_pca = cluster.splitDataLabeled(2,shap_values_pca,kmeans_pca.labels_)\n",
    "data_dict_org_pca = cluster.splitDataLabeled(2,org_values_pca,kmeans_org_pca.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_instanced = pd.concat((pd.DataFrame(org_values_pca),pd.DataFrame(columns = ['instance'])),axis = 1)\n",
    "pca_instanced['instance'].loc[X_train.index] = 'train'\n",
    "pca_instanced['instance'].loc[X_test.index] = 'test'\n",
    "shap_pca_instanced = pd.concat((pd.DataFrame(shap_values_pca),pd.DataFrame(columns = ['instance'])),axis = 1)\n",
    "shap_pca_instanced['instance'].loc[X_train.index] = 'train'\n",
    "shap_pca_instanced['instance'].loc[X_test.index] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shap_pca = cluster.convertOriginalData(data_dict_shap_pca,shap_pca_instanced,y_instanced)\n",
    "original_pca = cluster.convertOriginalData(data_dict_org_pca,pca_instanced,y_instanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train split XGBoost models over original data\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 1,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y),\n",
    "    \"eval_metric\": \"rmse\"\n",
    "}\n",
    "eval_results_org_pca = {}\n",
    "kwargs = {\n",
    "    'num_boost_round':10000,\n",
    "    'verbose_eval': 1000,\n",
    "    'evals_result' : {},\n",
    "    'early_stopping_rounds' : 200\n",
    "}\n",
    "model_dict_org_pca,eval_results_org_pca = cluster.trainMultipleModels(xgboost.train,original_pca,'XGBoost',params,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train split XGBoost models over original data\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 1,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y),\n",
    "    \"eval_metric\": \"rmse\"\n",
    "}\n",
    "eval_results_shap_pca = {}\n",
    "kwargs = {\n",
    "    'num_boost_round':10000,\n",
    "    'verbose_eval': 1000,\n",
    "    'evals_result' : {},\n",
    "    'early_stopping_rounds' : 200\n",
    "}\n",
    "model_dict_shap_pca,eval_results_shap_pca = cluster.trainMultipleModels(xgboost.train,original_shap_pca,'XGBoost',params,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "rmse_array = []\n",
    "for i in range(2):\n",
    "    sizes.append(len(original_shap_pca['original_test_label_cluster{0}'.format(i)]))\n",
    "    rmse_array.append(min(eval_results_shap_pca['eval{0}'.format(i)]['test']['rmse']))\n",
    "tot_rmse_shap_pca = metrics.ensembleRMSE(sizes,rmse_array)\n",
    "\n",
    "sizes = []\n",
    "rmse_array = []\n",
    "for i in range(2):\n",
    "    sizes.append(len(original_pca['original_test_label_cluster{0}'.format(i)]))\n",
    "    rmse_array.append(min(eval_results_org_pca['eval{0}'.format(i)]['test']['rmse']))\n",
    "tot_rmse_org_pca = metrics.ensembleRMSE(sizes,rmse_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(eval_results_shap_pca['eval0']['test']['rmse'])),eval_results_shap_pca['eval0']['test']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shap_pca['eval1']['test']['rmse'])),eval_results_shap_pca['eval1']['test']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shap_pca['eval0']['train']['rmse'])),eval_results_shap_pca['eval0']['train']['rmse'])\n",
    "plt.plot(np.arange(len(eval_results_shap_pca['eval1']['train']['rmse'])),eval_results_shap_pca['eval1']['train']['rmse'])\n",
    "plt.xlabel('Epoch count')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(['Model0-Test','Model1-Test','Model0-Train','Model1-Train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure()\n",
    "plt.barh(['Whole model','Original_ensemble','Shapley_ensemble','Shapley_ensemble + PCA','Original_ensemble + PCA'],[tot_result_big_model,tot_rmse_org,tot_rmse_shap,tot_rmse_shap_pca,tot_rmse_org_pca])\n",
    "plt.title('Test-RMSE value vs. Method used')\n",
    "for i,v in enumerate([tot_result_big_model,tot_rmse_org,tot_rmse_shap,tot_rmse_shap_pca,tot_rmse_org_pca]):\n",
    "    plt.text(v , i + .05, '{0:.3f}'.format(v), color='blue', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
