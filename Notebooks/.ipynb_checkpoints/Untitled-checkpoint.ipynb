{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Small example\n",
    "!pip install graphviz\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install openml\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from shap_bootstrap import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import openml\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Users\\\\koral\\\\Documents\\\\release\\\\bin'\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from pyclustertend import hopkins\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,name = datasets.returnDataset(2)\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "#X.rename(columns = lambda x: x.replace(' ', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.90'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25]"
      ],
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list = list(range(26))\n",
    "dataset_list.pop(19)\n",
    "dataset_list.pop(18)\n",
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[16:04:56] src/objective/objective.cc:23: Unknown objective function req:squared",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-be26bf6fbc7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;34m\"max_depth\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     }\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mshap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mCVPack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[1;34m\"\"\"\"Auxiliary datastruct to hold one fold of CV.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;34m\"\"\"\"Initialize the CVPack\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Distributed code: need to resume to this point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0minterface_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1109\u001b[1;33m         \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mnthread\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnthread\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnthread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;31m# load the XGBoost library globally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [16:04:56] src/objective/objective.cc:23: Unknown objective function req:squared"
     ]
    }
   ],
   "source": [
    "org_data = []\n",
    "shap_data = []\n",
    "org_vals = []\n",
    "shap_vals = []\n",
    "for d in dataset_list[:2]:\n",
    "    X,y,name = datasets.returnDataset(d)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"req:squarederror\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\" : 3\n",
    "    }\n",
    "    model = xgb.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    org_vals.append(X)\n",
    "    shap_vals.append(shap_values)\n",
    "    #h_org = hopkins(X,len(X)//5)\n",
    "    #h_shap = hopkins(shap_values,len(shap_values)//5)\n",
    "    #org_data.append(h_org)\n",
    "    #shap_data.append(h_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(x= org,y = shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "ax.scatter(x=y_test,y = y_pred_b1)\n",
    "ax.scatter(x = y_test,y = y_pred_b8)\n",
    "ax.plot([0,25],[0,25],color = 'red',linestyle='--')\n",
    "ax.set_xlabel('True label')\n",
    "ax.set_ylabel('Pipeline predictions')\n",
    "ax.set_title('Divergence of predictions from true label')\n",
    "new_labels = ['Identity', 'XGBoost Model - RMSE: {:.3f}'.format(err_b1), 'Shap-bootstrap - RMSE: {:.3f}'.format(err_b8)]\n",
    "ax.legend(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old,_,_= datasets.returnDataset(0)\n",
    "scaler = StandardScaler()\n",
    "old_scale = scaler.fit_transform(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "explained_var_ratio = 0\n",
    "k = 1\n",
    "while explained_var_ratio < 0.95:\n",
    "    k += 1\n",
    "    try:\n",
    "        pca = PCA(n_components = k)\n",
    "    except:\n",
    "        pca = PCA(n_components = 1)  \n",
    "    pca.fit(X)\n",
    "    explained_var_ratio = pca.explained_variance_ratio_.sum()\n",
    "print(k)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(13,14):\n",
    "    X,y,name = datasets.returnDataset(k)\n",
    "    try:\n",
    "        pca = PCA(n_components = 3)\n",
    "        #pca.fit(X)\n",
    "    except:\n",
    "        pca = PCA(n_components = 1)\n",
    "    pca.fit(X)\n",
    "    print('Dataset : ',name , ' Variance_ratio : ', pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\" : 3\n",
    "}\n",
    "model = xgb.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model,xlabel='Frequency of appearance per feature')\n",
    "pl.title(\"XGBoost.plot_importance(model)\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_ind = np.random.randint(0,len(X),1000)\n",
    "background = X.iloc[back_ind,:]\n",
    "explainer = shap.TreeExplainer(model, data = background,feature_dependence=\"independent\", model_output='probability')\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pd.DataFrame(shap_values,columns = X.columns)\n",
    "shap_train, shap_test, y_train, y_test = train_test_split(shap_df, y, test_size=0.2, random_state=7)\n",
    "d_train = xgb.DMatrix(shap_train, label=y_train)\n",
    "d_test = xgb.DMatrix(shap_test, label=y_test)\n",
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\" : 3\n",
    "}\n",
    "model_shap= xgb.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('CGPA', shap_values, X, display_features=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "explained_var_ratio = 0\n",
    "k = 1\n",
    "while explained_var_ratio < 0.95:\n",
    "    k += 1\n",
    "    try:\n",
    "        pca = PCA(n_components = k)\n",
    "    except:\n",
    "        pca = PCA(n_components = 1)  \n",
    "    pca.fit(X)\n",
    "    explained_var_ratio = pca.explained_variance_ratio_.sum()\n",
    "pca2 = pca.transform(X)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
    "labels = kmeans.predict(X)\n",
    "#plt.scatter(pca2[:,0],pca2[:,1],labels)\n",
    "#plt.scatter(X['CGPA'][:1000],y[:1000],c = labels[:1000])\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_var_ratio = 0\n",
    "k = 1\n",
    "while explained_var_ratio < 0.95:\n",
    "    k += 1\n",
    "    try:\n",
    "        pca = PCA(n_components = k)\n",
    "    except:\n",
    "        pca = PCA(n_components = 1)  \n",
    "    pca.fit(shap_values)\n",
    "    explained_var_ratio = pca.explained_variance_ratio_.sum()\n",
    "pca3 = pca.transform(shap_values)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(shap_values)\n",
    "labels_shap = kmeans.predict(shap_values)\n",
    "#plt.scatter(pca3[:,0],pca3[:,1],labels_shap)\n",
    "#plt.scatter(X['CGPA'][:1000],y[:1000],c = labels_shap[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_org = silhouette_score(X,labels)\n",
    "silhouette_shap = silhouette_score(shap_values,labels_shap)\n",
    "silhouette_org_shap = silhouette_score(X,labels_shap)\n",
    "print('Silhouette score of original cluster : {} Silhouette score of Shapley cluster {} Silhouette score of Original features w/ Shapley cluster {}'.format(silhouette_org,silhouette_shap,silhouette_org_shap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca3[:,0],pca3[:,1],c = labels_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca2[:,0],pca2[:,1],c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# We only take the two corresponding features\n",
    "X_plt = X.loc[:,['CGPA','GRE_Score']]\n",
    "y_plt = labels\n",
    "n_classes = 3\n",
    "plot_colors = \"ryb\"\n",
    "plot_step = 0.02\n",
    "# Train\n",
    "clf = DecisionTreeRegressor().fit(X_plt, y)\n",
    "x_min, x_max = X_plt.iloc[:, 0].min() - 1, X_plt.iloc[:, 0].max() + 1\n",
    "y_min, y_max = y.min() - 1, y.max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                     np.arange(y_min, y_max, plot_step))\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('GRE_Score')\n",
    "\n",
    "# Plot the training points\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(y_plt == i)\n",
    "    plt.scatter(X.iloc[idx]['CGPA'], y[idx], c=color, label='Class {}'.format(i),\n",
    "                    cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# We only take the two corresponding features\n",
    "X_plt = X.loc[:,['CGPA','GRE_Score']]\n",
    "y_plt = labels_shap\n",
    "n_classes = 3\n",
    "plot_colors = \"ryb\"\n",
    "plot_step = 0.02\n",
    "# Train\n",
    "clf = DecisionTreeRegressor().fit(X_plt, y)\n",
    "x_min, x_max = X_plt.iloc[:, 0].min() - 1, X_plt.iloc[:, 0].max() + 1\n",
    "y_min, y_max = y.min() - 1, y.max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                     np.arange(y_min, y_max, plot_step))\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('GRE_Score')\n",
    "\n",
    "# Plot the training points\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(y_plt == i)\n",
    "    plt.scatter(X.iloc[idx]['CGPA'], y[idx], c=color, label='Class {}'.format(i),\n",
    "                    cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "cdict1 = {\n",
    "    'red': ((0.0, 0.11764705882352941, 0.11764705882352941),\n",
    "            (1.0, 0.9607843137254902, 0.9607843137254902)),\n",
    "\n",
    "    'green': ((0.0, 0.5333333333333333, 0.5333333333333333),\n",
    "              (1.0, 0.15294117647058825, 0.15294117647058825)),\n",
    "\n",
    "    'blue': ((0.0, 0.8980392156862745, 0.8980392156862745),\n",
    "             (1.0, 0.3411764705882353, 0.3411764705882353)),\n",
    "\n",
    "    'alpha': ((0.0, 1, 1),\n",
    "              (0.5, 1, 1),\n",
    "              (1.0, 1, 1))\n",
    "}  # #1E88E5 -> #ff0052\n",
    "red_blue_solid = LinearSegmentedColormap('RedBlue', cdict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5),frameon = False)\n",
    "colors = ['blue','purple','red']\n",
    "for i in np.unique(labels):\n",
    "    idx = labels == i\n",
    "    pl.scatter(X['CGPA'][idx],\n",
    "               y[idx],\n",
    "               color = colors[i],\n",
    "               #explainer.expected_value + shap_values[:2000,:].sum(1).astype(np.float64),\n",
    "               linewidth=0, alpha=1., cmap=red_blue_solid,label = 'Cluster {}'.format(i+1))\n",
    "#cb = pl.colorbar(label=\"Cluster labels\", aspect=40, orientation=\"horizontal\" , ticks = np.arange(3))\n",
    "#cb.set_alpha(1)\n",
    "#cb.draw_all()\n",
    "#cb.outline.set_linewidth(0)\n",
    "#cb.ax.tick_params('x', length=0)\n",
    "#cb.ax.yaxis.set_label_position('right')\n",
    "#pl.gca().axis(\"off\")\n",
    "#pl.gca().axes.get_yaxis().set_visible(False)\n",
    "pl.xlabel(\"CGPA of Student\")\n",
    "pl.ylabel(\"Probability of admission\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X,columns = old.columns)\n",
    "f = pl.figure(figsize=(5,5),frameon = False)\n",
    "colors = ['blue','purple','red']\n",
    "for i in np.unique(labels_shap):\n",
    "    idx = labels == i\n",
    "    pl.scatter(X_df['TOEFL Score'][idx],\n",
    "               y[idx],\n",
    "               color = colors[i],\n",
    "               #explainer.expected_value + shap_values[:2000,:].sum(1).astype(np.float64),\n",
    "               linewidth=0, alpha=1., cmap=red_blue_solid,label = 'Cluster {}'.format(i+1))\n",
    "#cb = pl.colorbar(label=\"Cluster labels\", aspect=40, orientation=\"horizontal\" , ticks = np.arange(3))\n",
    "#cb.set_alpha(1)\n",
    "#cb.draw_all()\n",
    "#cb.outline.set_linewidth(0)\n",
    "#cb.ax.tick_params('x', length=0)\n",
    "#cb.ax.yaxis.set_label_position('right')\n",
    "#pl.gca().axis(\"off\")\n",
    "#pl.gca().axes.get_yaxis().set_visible(False)\n",
    "pl.xlabel(\"CGPA of Student\")\n",
    "pl.ylabel(\"Probability of admission\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(pca2[:,0],\n",
    "           pca2[:,1],\n",
    "           c=pca2.sum(1).astype(np.float64),\n",
    "           linewidth=0, alpha=1., cmap=red_blue_solid)\n",
    "cb = pl.colorbar(label=\"Log odds of making > $50K\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(model,num_trees=0, rankdir='TB')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(model_shap,num_trees=0, rankdir='TB')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "dtree=DecisionTreeRegressor()\n",
    "dtree.fit(X,y)\n",
    "# We only take the two corresponding features\n",
    "X_plt = X.loc[:,['LOR_','Research']]\n",
    "y_plt = y\n",
    "n_classes = 1\n",
    "plot_colors = \"ryb\"\n",
    "plot_step = 0.02\n",
    "# Train\n",
    "clf = DecisionTreeRegressor().fit(X_plt, y_plt)\n",
    "x_min, x_max = X_plt.iloc[:, 0].min() - 1, X_plt.iloc[:, 0].max() + 1\n",
    "y_min, y_max = X_plt.iloc[:, 1].min() - 1, X_plt.iloc[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                     np.arange(y_min, y_max, plot_step))\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('GRE_Score')\n",
    "# Plot the training points\n",
    "labels = clf.predict(X_plt)\n",
    "plt.scatter(X_plt.iloc[:, 0], X_plt.iloc[:, 1], c=labels, label='Admission Probability',\n",
    "                cmap=plt.cm.RdYlBu, edgecolor='black', s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value,shap_values[152,:],X.iloc[152,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y == 0.86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value,shap_values[2,:],X.iloc[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distance.euclidean(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distance.correlation(shap_values, shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(np.array(X.iloc[2]).reshape(1,-1),np.array(X.iloc[13]).reshape(1,-1))\n",
    "print('Cosine similarity: %.3f' % cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(np.array(shap_values[2]).reshape(1,-1),np.array(shap_values[13]).reshape(1,-1))\n",
    "print('Cosine similarity: %.3f' % cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pyclustertend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_scale = scale(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm = ivat(X_scale,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm_shap = vat(shap_values_scale,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
