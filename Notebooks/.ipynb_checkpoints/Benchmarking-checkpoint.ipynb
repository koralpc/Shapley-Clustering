{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is the benchmark notebook, where test results of each test notebook is combined together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(benchmark,normalize = True):\n",
    "    if normalize:\n",
    "        benchmark_norm = benchmark.iloc[:,2:-3].div(benchmark.sum(axis=1), axis=0)\n",
    "        key = 'Normalized'\n",
    "    else:\n",
    "        benchmark_norm = benchmark.iloc[:,2:-3]\n",
    "        key = 'Un-Normalized'\n",
    "    plt.figure()\n",
    "    y = np.arange(len(benchmark_norm.columns))\n",
    "    col_labels = np.array(benchmark_norm.columns)\n",
    "    for i in range(len(benchmark)):\n",
    "        y_pos = y + i * (1/(2*len(col_labels)))\n",
    "        plt.barh(y_pos,benchmark_norm.iloc[i,:],height = 1/(2*len(col_labels)),label = benchmark['Data_Type'][i] +  benchmark['Explainer_Type'][i][:3] +benchmark['Model_Type'][i][:3])\n",
    "    plt.yticks([r + (1/(len(col_labels))) for r in range(len(y))], col_labels)\n",
    "    plt.legend()\n",
    "    plt.title(key + ' test errors in different datasets vs. method used (Trained over {0} via explainer {1} & model {2})'.format(benchmark.iloc[0,-3],benchmark.iloc[0,-2],benchmark.iloc[0,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "#%run \"Shapley_Clustering_Boston_Dataset.ipynb\"\n",
    "#%run \"Shapley_Clustering_Crime_Dataset.ipynb\"\n",
    "\n",
    "for c in [0,3,4,6,7]:\n",
    "    for nC in [2,4]:\n",
    "        for i in ['Original']:\n",
    "            for j in ['Linear']:\n",
    "                for k in ['XGBoost']:\n",
    "                    !python Shapley_Clustering_Blackbox.py $i $j $k $nC $c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "for i in range(1,2):\n",
    "    !python Shapley_Clustering_Blackbox.py Original XGBoost XGBoost 3 $i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,2):\n",
    "    !python ../Framework/custom_sklearn_pipeline.py Original XGBoost XGBoost 3 $i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(10):\n",
    "    for nC in [3,5]:\n",
    "        for i in ['Original-PCA','Shapley-PCA']:\n",
    "            for j in ['Linear','XGBoost']:\n",
    "                for k in ['XGBoost']:\n",
    "                    !python Shapley_Clustering_PCA_Blackbox.py $i $j $k $nC $c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "benchmark_df = pd.read_csv('../Data/test_pca.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsl1 = benchmark_df.groupby('Dataset_name').agg({'Explainer_model' : min})\n",
    "bsl2 = benchmark_df.groupby('Dataset_name').agg({'Original_ensemble' : min})\n",
    "bsl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(benchmark_df['Dataset_name'])):\n",
    "    benchmark_df['Explainer_model'].iloc[j] = bsl1.loc[benchmark_df['Dataset_name'].iloc[j]][0]\n",
    "    benchmark_df['Original_ensemble'].iloc[j] = bsl2.loc[benchmark_df['Dataset_name'].iloc[j]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#benchmark_df_min = benchmark_df[(benchmark_df['Explainer_model'] > benchmark_df['Shapley_ensemble']) & (benchmark_df['Original_ensemble'] > benchmark_df['Shapley_ensemble'])]\n",
    "benchmark_df_min = benchmark_df\n",
    "bsl1_improvement = (benchmark_df_min['Explainer_model'] - benchmark_df_min['Shapley_ensemble']).divide(benchmark_df_min['Explainer_model'])\n",
    "bsl2_improvement = (benchmark_df_min['Original_ensemble'] - benchmark_df_min['Shapley_ensemble']).divide(benchmark_df_min['Original_ensemble'])\n",
    "benchmark_df_min['Percentage_Improvement'] = round(100 * (bsl1_improvement+bsl2_improvement)/2,1)\n",
    "benchmark_df_min = benchmark_df_min.loc[benchmark_df_min['Percentage_Improvement'] > 0]\n",
    "benchmark_df_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_datatype_grouped = benchmark_df_min.groupby('Data_Type').agg({'Percentage_Improvement':np.mean})\n",
    "bench_dataset_grouped = benchmark_df_min.groupby(['Dataset_name']).agg({'Percentage_Improvement':np.mean, 'Data_Type':'nunique'})\n",
    "bench_dataset_grouped = bench_dataset_grouped[bench_dataset_grouped['Data_Type'] == 1]\n",
    "benchmark_df_min = benchmark_df_min[benchmark_df_min['Dataset_name'] != 'NYE_Airbnb']\n",
    "bench_datatype_grouped = benchmark_df_min.groupby(['Data_Type','Dataset_name']).agg({'Percentage_Improvement':np.mean})\n",
    "bench_dataset_grouped = benchmark_df_min.groupby(['Dataset_name','Data_Type']).agg({'Percentage_Improvement':np.mean})\n",
    "bench_datatype_grouped = bench_datatype_grouped.groupby('Data_Type').mean()\n",
    "bench_dataset_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(y =bench_datatype_grouped.index ,x ='Percentage_Improvement',data = bench_datatype_grouped)\n",
    "g.set_title ('Percentage improvement over all methods and datasets for given feature space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= sns.barplot(y =bench_dataset_grouped.index ,x ='Percentage_Improvement',data = bench_dataset_grouped)\n",
    "g.set_title('Percentage improvement in rmse over all models for given dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = benchmark_df_min.groupby(['Data_Type','Explainer_Type','Ensemble_model_Type']).agg({'Dataset_name':'nunique','Percentage_Improvement':np.mean})\n",
    "data_min['Percentage_Improvement'] = round(data_min['Percentage_Improvement'],1)\n",
    "data_min.columns = ['Dataset_count','Percentage_Improvement']\n",
    "best_params = data_min['Dataset_count'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grouped = benchmark_df_min.groupby(['Data_Type','Explainer_Type','Ensemble_model_Type','Dataset_name'])\n",
    "params_grouped_df = params_grouped.agg({'Explainer_model' : min ,'Original_ensemble':min, 'Shapley_ensemble' : min,'Percentage_Improvement':np.mean})\n",
    "best_params_results = params_grouped_df.loc[best_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets = benchmark_df[(benchmark_df.Data_Type == best_params[0]) & (benchmark_df.Explainer_Type == best_params[1]) & (benchmark_df.Ensemble_model_Type == best_params[2])]\n",
    "#sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(y =best_params_results.index ,x ='Percentage_Improvement',data = best_params_results)\n",
    "g.set_title('Percentage improvement in rmse for Feature Space: {0} /Explainer(M_e): {1} /Leaf_Model(M_c1): {2}'.format(best_params[0],best_params[1],best_params[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = benchmark_df.groupby(['Data_Type','Explainer_Type','Ensemble_model_Type','Dataset_name'])\n",
    "data_min_df = data_min.agg({'Explainer_model' : min ,'Original_ensemble':min, 'Shapley_ensemble' : min})\n",
    "data_real_min = data_min_df[(data_min_df['Explainer_model'] > data_min_df['Shapley_ensemble']) & (data_min_df['Original_ensemble'] > data_min_df['Shapley_ensemble'])]\n",
    "bsl1_improvement = (data_real_min['Explainer_model'] - data_real_min['Shapley_ensemble']).divide(data_real_min['Explainer_model'])\n",
    "bsl2_improvement = (data_real_min['Original_ensemble'] - data_real_min['Shapley_ensemble']).divide(data_real_min['Original_ensemble'])\n",
    "data_real_min['Avg_Percentage_Improvement'] = 100 * (bsl1_improvement+bsl2_improvement)/2\n",
    "data_real_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = benchmark_df.groupby(['Data_Type','Explainer_Type','Ensemble_model_Type','Dataset_name'])\n",
    "data_min_df = data_min.agg({'Explainer_model' : min ,'Original_ensemble':min, 'Shapley_ensemble' : min})\n",
    "data_real_min = data_min_df[(data_min_df['Explainer_model'] > data_min_df['Shapley_ensemble']) & (data_min_df['Original_ensemble'] > data_min_df['Shapley_ensemble'])]\n",
    "bsl1_improvement = (data_real_min['Explainer_model'] - data_real_min['Shapley_ensemble']).divide(data_real_min['Explainer_model'])\n",
    "bsl2_improvement = (data_real_min['Original_ensemble'] - data_real_min['Shapley_ensemble']).divide(data_real_min['Original_ensemble'])\n",
    "data_real_min['Avg_Percentage_Improvement'] = 100 * (bsl1_improvement+bsl2_improvement)/2\n",
    "data_real_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real_min2 = data_real_min['Shapley_ensemble'].groupby(['Data_Type','Ensemble_model_Type','Explainer_Type']).count()\n",
    "data_param_count = data_real_min2.groupby(['Data_Type','Explainer_Type','Ensemble_model_Type']).sum()\n",
    "data_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = benchmark_df.groupby(['Data_Type','Cluster_count','Explainer_Type','Ensemble_model_Type','Dataset_name'])\n",
    "data_min_df = data_min.agg({'Explainer_model' : min ,'Original_ensemble':min, 'Shapley_ensemble' : min})\n",
    "data_real_min = data_min_df[(data_min_df['Explainer_model'] > data_min_df['Shapley_ensemble']) & (data_min_df['Original_ensemble'] > data_min_df['Shapley_ensemble'])]\n",
    "data_real_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real_min2 = data_real_min['Shapley_ensemble'].groupby(['Data_Type','Cluster_count','Ensemble_model_Type','Explainer_Type']).count()\n",
    "data_param_count = data_real_min2.groupby(['Data_Type','Cluster_count','Explainer_Type','Ensemble_model_Type']).sum()\n",
    "data_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df = pd.read_csv('../Data/test_results_all_data.txt')\n",
    "bsl1 = benchmark_df.groupby('Dataset_name').agg({'Explainer_model' : min})\n",
    "bsl2 = benchmark_df.groupby('Dataset_name').agg({'Original_ensemble' : min})\n",
    "for j in range(len(benchmark_df['Dataset_name'])):\n",
    "    benchmark_df['Explainer_model'].iloc[j] = bsl1.loc[benchmark_df['Dataset_name'].iloc[j]][0]\n",
    "    benchmark_df['Original_ensemble'].iloc[j] = bsl2.loc[benchmark_df['Dataset_name'].iloc[j]][0]\n",
    "data_min = benchmark_df.groupby(['Data_Type','Explainer_Type','Ensemble_model_Type','Dataset_name'])\n",
    "data_min_df = data_min.agg({'Explainer_model' : min ,'Original_ensemble':min, 'Shapley_ensemble' : min})\n",
    "data_real_min = data_min_df[(data_min_df['Explainer_model'] > data_min_df['Shapley_ensemble']) & (data_min_df['Original_ensemble'] > data_min_df['Shapley_ensemble'])]\n",
    "data_real_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real_min2 = data_real_min['Shapley_ensemble'].groupby(['Data_Type','Ensemble_model_Type','Explainer_Type']).count()\n",
    "data_param_count = data_real_min2.groupby(['Data_Type','Explainer_Type','Ensemble_model_Type']).sum()\n",
    "data_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = benchmark_df.groupby(['Data_Type','Cluster_count','Explainer_Type','Ensemble_model_Type','Dataset_name'])\n",
    "data_min_df = data_min.agg({'Explainer_model' : min ,'Original_ensemble':min, 'Shapley_ensemble' : min})\n",
    "data_real_min = data_min_df[(data_min_df['Explainer_model'] > data_min_df['Shapley_ensemble']) & (data_min_df['Original_ensemble'] > data_min_df['Shapley_ensemble'])]\n",
    "data_real_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real_min2 = data_real_min['Shapley_ensemble'].groupby(['Data_Type','Cluster_count','Ensemble_model_Type','Explainer_Type']).count()\n",
    "data_param_count = data_real_min2.groupby(['Data_Type','Cluster_count','Explainer_Type','Ensemble_model_Type']).sum()\n",
    "data_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df_bst = benchmark_df_min[benchmark_df_min['Dataset_name'] == 'Amazon']\n",
    "benchmark_df_org = benchmark_df_bst[(benchmark_df_bst['Data_Type'] == 'Original')]\n",
    "benchmark_df_shap = benchmark_df_bst[(benchmark_df_bst['Data_Type'] == 'Shapley')]\n",
    "benchmark_df_org.reset_index(inplace = True)\n",
    "benchmark_df_shap.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_melted_org = pd.melt(benchmark_df_org.iloc[:,[2,3,4,5,7,8]] , id_vars = ['Explainer_Type','Ensemble_model_Type','Cluster_count'], value_vars= ['Explainer_model','Original_ensemble','Shapley_ensemble'])\n",
    "#benchmark_melted_org.drop_duplicates(benchmark_melted_org.columns[[0,3,4]],inplace = True)\n",
    "benchmark_melted_org.rename(columns = {'variable':'Model','value':'rmse'},inplace = True)\n",
    "g= sns.catplot(x = 'Explainer_Type',y = 'rmse', hue = 'Model',col = 'Ensemble_model_Type',row = 'Cluster_count',kind = 'bar',data = benchmark_melted_org)\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Test-rmse results for dataset: {0} with training via: {1}'.format(benchmark_df_org['Dataset_name'].iloc[0], benchmark_df_org['Data_Type'].iloc[0]), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_melted_shap = pd.melt(benchmark_df_shap.iloc[:,[2,3,4,5,7,8]] , id_vars = ['Explainer_Type','Ensemble_model_Type','Cluster_count'], value_vars= ['Explainer_model','Original_ensemble','Shapley_ensemble'])\n",
    "#benchmark_melted_shap.drop_duplicates(benchmark_melted_shap.columns[[0,3,4]],inplace = True)\n",
    "benchmark_melted_shap.rename(columns = {'variable':'Model','value':'rmse'},inplace = True)\n",
    "g= sns.catplot(x = 'Explainer_Type',y = 'rmse', hue = 'Model',col = 'Ensemble_model_Type',row = 'Cluster_count',kind = 'bar',data = benchmark_melted_shap)\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Test-rmse results for dataset: {0} with training via: {1}'.format(benchmark_df_shap['Dataset_name'].iloc[0], benchmark_df_shap['Data_Type'].iloc[0]), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:.2f}\".format(3.54662))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openml tpot h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from openml import datasets\n",
    "from openml import tasks\n",
    "from openml import runs\n",
    "from openml import flows\n",
    "from openml import extensions\n",
    "openml.config.apikey = '7be8de439f25368679e0802040791d1f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Framework.custom_sklearn_pipeline import CustomPipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'Shapley-Blackbox', 'Shapley-Blackbox__ensemble_type', 'Shapley-Blackbox__explainer_type', 'Shapley-Blackbox__nClusters', 'Shapley-Blackbox__notebook_mode'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapley_pipeline = CustomPipelineModel('Shapley','Linear','XGBoost',3)\n",
    "shapley_pipeline.pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Shapley-Blackbox', OpenML Flow\n",
       "              ===========\n",
       "              Flow Name.......: Framework.custom_sklearn_pipeline.CustomPipelineModel\n",
       "              Flow Description: Thesis work v0.1\n",
       "              Dependencies....: sklearn==0.20.1\n",
       "              numpy>=1.6.1\n",
       "              scipy>=0.9)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_learn_ext = extensions.sklearn.SklearnExtension()\n",
    "flow = sk_learn_ext.model_to_flow(shapley_pipeline.pipeline)\n",
    "flow.components['Shapley-Blackbox'].description = 'Thesis work v0.1'\n",
    "flow.components\n",
    "task = tasks.get_task(52948)\n",
    "run = runs.run_flow_on_task(flow,task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_learn_ext.obtain_parameter_values(flow,shapley_pipeline.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "scores = run.get_metric_fn(metrics.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.79867536,  9.03097311, 14.46789172,  7.16684439, 11.98255269,\n",
       "        9.28219723,  5.64705949, 11.62064952, 13.06205899,  9.79941809])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.64705948567227"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [12:57:28:openml.flows.flow] Flow 'Framework.custom_sklearn_pipeline.CustomPipelineModel's empty description\n"
     ]
    },
    {
     "ename": "OpenMLServerException",
     "evalue": "\n<oml:flow xmlns:oml=\"http://openml.org/openml\">\n\t<oml:name>sklearn.pipeline.Pipeline(Shapley-Blackbox=Framework.custom_sklearn_pipeline.CustomPipelineModel)</oml:name>\n\t<oml:custom_name>sklearn.Pipeline(CustomPipelineModel)</oml:custom_name>\n\t<oml:class_name>sklearn.pipeline.Pipeline</oml:class_name>\n\t<oml:external_version>Framework==0.0.1,openml==0.10.2,sklearn==0.20.1</oml:external_version>\n\t<oml:description>Pipeline of transforms with a final estimator.\n\nSequentially apply a list of transforms and a final estimator.\nIntermediate steps of the pipeline must be 'transforms', that is, they\nmust implement fit and transform methods.\nThe final estimator only needs to implement fit.\nThe transformers in the pipeline can be cached using ``memory`` argument.\n\nThe purpose of the pipeline is to assemble several steps that can be\ncross-validated together while setting different parameters.\nFor this, it enables setting parameters of the various steps using their\nnames and the parameter name separated by a '__', as in the example below.\nA step's estimator may be replaced entirely by setting the parameter\nwith its name to another estimator, or a transformer removed by setting\nto None.</oml:description>\n\t<oml:language>English</oml:language>\n\t<oml:dependencies>sklearn==0.20.1\nnumpy&gt;=1.6.1\nscipy&gt;=0.9</oml:dependencies>\n\t<oml:parameter>\n\t\t<oml:name>memory</oml:name>\n\t\t<oml:data_type>None</oml:data_type>\n\t\t<oml:default_value>null</oml:default_value>\n\t\t<oml:description>Used to cache the fitted transformers of the pipeline. By default,\n    no caching is performed. If a string is given, it is the path to\n    the caching directory. Enabling caching triggers a clone of\n    the transformers before fitting. Therefore, the transformer\n    instance given to the pipeline cannot be inspected\n    directly. Use the attribute ``named_steps`` or ``steps`` to\n    inspect estimators within the pipeline. Caching the\n    transformers is advantageous when fitting is time consuming.</oml:description>\n\t</oml:parameter>\n\t<oml:parameter>\n\t\t<oml:name>steps</oml:name>\n\t\t<oml:data_type>list</oml:data_type>\n\t\t<oml:default_value>[{\"oml-python:serialized_object\": \"component_reference\", \"value\": {\"key\": \"Shapley-Blackbox\", \"step_name\": \"Shapley-Blackbox\"}}]</oml:default_value>\n\t\t<oml:description>List of (name, transform) tuples (implementing fit/transform) that are\n    chained, in the order in which they are chained, with the last object\n    an estimator</oml:description>\n\t</oml:parameter>\n\t<oml:component>\n\t\t<oml:identifier>Shapley-Blackbox</oml:identifier>\n\t\t<oml:flow xmlns:oml=\"http://openml.org/openml\">\n\t\t\t<oml:name>Framework.custom_sklearn_pipeline.CustomPipelineModel</oml:name>\n\t\t\t<oml:custom_name>Framework.CustomPipelineModel</oml:custom_name>\n\t\t\t<oml:class_name>Framework.custom_sklearn_pipeline.CustomPipelineModel</oml:class_name>\n\t\t\t<oml:external_version>Framework==0.0.1,openml==0.10.2,sklearn==0.20.1</oml:external_version>\n\t\t\t<oml:description></oml:description>\n\t\t\t<oml:language>English</oml:language>\n\t\t\t<oml:dependencies>sklearn==0.20.1\nnumpy&gt;=1.6.1\nscipy&gt;=0.9</oml:dependencies>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>ensemble_type</oml:name>\n\t\t\t\t<oml:default_value>\"XGBoost\"</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>explainer_type</oml:name>\n\t\t\t\t<oml:default_value>\"Linear\"</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>nClusters</oml:name>\n\t\t\t\t<oml:default_value>3</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>notebook_mode</oml:name>\n\t\t\t\t<oml:default_value>\"Shapley\"</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:tag>openml-python</oml:tag>\n\t\t\t<oml:tag>sklearn</oml:tag>\n\t\t\t<oml:tag>scikit-learn</oml:tag>\n\t\t\t<oml:tag>python</oml:tag>\n\t\t\t<oml:tag>sklearn_0.20.1</oml:tag>\n\t\t</oml:flow>\n\t</oml:component>\n\t<oml:tag>openml-python</oml:tag>\n\t<oml:tag>sklearn</oml:tag>\n\t<oml:tag>scikit-learn</oml:tag>\n\t<oml:tag>python</oml:tag>\n\t<oml:tag>sklearn_0.20.1</oml:tag>\n</oml:flow>\nProblem validating uploaded description file - XML does not correspond to XSD schema. Error Element '{http://openml.org/openml}description': [facet 'minLength'] The value has a length of '0'; this underruns the allowed minimum length of '1'.\n on line 53 column 0. Error Element '{http://openml.org/openml}description': '' is not a valid value of the atomic type '{http://openml.org/openml}basic_latin1024'.\n on line 53 column 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenMLServerException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-76de1bcea102>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmyrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openml\\base.py\u001b[0m in \u001b[0;36mpublish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpublish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'OpenMLBase'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mfile_elements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_file_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'description'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_elements\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openml\\runs\\run.py\u001b[0m in \u001b[0;36m_get_file_elements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[1;31m# publish the linked Flow before publishing the run.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openml\\flows\\flow.py\u001b[0m in \u001b[0;36mpublish\u001b[1;34m(self, raise_error_if_exists)\u001b[0m\n\u001b[0;32m    386\u001b[0m                 raise openml.exceptions.PyOpenMLError(\"Flow does not exist on the server, \"\n\u001b[0;32m    387\u001b[0m                                                       \"but 'flow.flow_id' is not None.\")\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             \u001b[0mflow_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mraise_error_if_exists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openml\\base.py\u001b[0m in \u001b[0;36mpublish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{}/'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_rest_api_type_alias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         response_text = openml._api_calls._perform_api_call(\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_elements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         )\n\u001b[0;32m    132\u001b[0m         \u001b[0mxml_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxmltodict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openml\\_api_calls.py\u001b[0m in \u001b[0;36m_perform_api_call\u001b[1;34m(call, request_method, data, file_elements)\u001b[0m\n\u001b[0;32m     51\u001b[0m             raise ValueError('request method must be post when file elements '\n\u001b[0;32m     52\u001b[0m                              'are present')\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read_url_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_elements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_elements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openml\\_api_calls.py\u001b[0m in \u001b[0;36m_read_url_files\u001b[1;34m(url, data, file_elements)\u001b[0m\n\u001b[0;32m     84\u001b[0m     )\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0m_parse_server_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_elements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_elements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'Content-Encoding'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Content-Encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'gzip'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOpenMLServerException\u001b[0m: \n<oml:flow xmlns:oml=\"http://openml.org/openml\">\n\t<oml:name>sklearn.pipeline.Pipeline(Shapley-Blackbox=Framework.custom_sklearn_pipeline.CustomPipelineModel)</oml:name>\n\t<oml:custom_name>sklearn.Pipeline(CustomPipelineModel)</oml:custom_name>\n\t<oml:class_name>sklearn.pipeline.Pipeline</oml:class_name>\n\t<oml:external_version>Framework==0.0.1,openml==0.10.2,sklearn==0.20.1</oml:external_version>\n\t<oml:description>Pipeline of transforms with a final estimator.\n\nSequentially apply a list of transforms and a final estimator.\nIntermediate steps of the pipeline must be 'transforms', that is, they\nmust implement fit and transform methods.\nThe final estimator only needs to implement fit.\nThe transformers in the pipeline can be cached using ``memory`` argument.\n\nThe purpose of the pipeline is to assemble several steps that can be\ncross-validated together while setting different parameters.\nFor this, it enables setting parameters of the various steps using their\nnames and the parameter name separated by a '__', as in the example below.\nA step's estimator may be replaced entirely by setting the parameter\nwith its name to another estimator, or a transformer removed by setting\nto None.</oml:description>\n\t<oml:language>English</oml:language>\n\t<oml:dependencies>sklearn==0.20.1\nnumpy&gt;=1.6.1\nscipy&gt;=0.9</oml:dependencies>\n\t<oml:parameter>\n\t\t<oml:name>memory</oml:name>\n\t\t<oml:data_type>None</oml:data_type>\n\t\t<oml:default_value>null</oml:default_value>\n\t\t<oml:description>Used to cache the fitted transformers of the pipeline. By default,\n    no caching is performed. If a string is given, it is the path to\n    the caching directory. Enabling caching triggers a clone of\n    the transformers before fitting. Therefore, the transformer\n    instance given to the pipeline cannot be inspected\n    directly. Use the attribute ``named_steps`` or ``steps`` to\n    inspect estimators within the pipeline. Caching the\n    transformers is advantageous when fitting is time consuming.</oml:description>\n\t</oml:parameter>\n\t<oml:parameter>\n\t\t<oml:name>steps</oml:name>\n\t\t<oml:data_type>list</oml:data_type>\n\t\t<oml:default_value>[{\"oml-python:serialized_object\": \"component_reference\", \"value\": {\"key\": \"Shapley-Blackbox\", \"step_name\": \"Shapley-Blackbox\"}}]</oml:default_value>\n\t\t<oml:description>List of (name, transform) tuples (implementing fit/transform) that are\n    chained, in the order in which they are chained, with the last object\n    an estimator</oml:description>\n\t</oml:parameter>\n\t<oml:component>\n\t\t<oml:identifier>Shapley-Blackbox</oml:identifier>\n\t\t<oml:flow xmlns:oml=\"http://openml.org/openml\">\n\t\t\t<oml:name>Framework.custom_sklearn_pipeline.CustomPipelineModel</oml:name>\n\t\t\t<oml:custom_name>Framework.CustomPipelineModel</oml:custom_name>\n\t\t\t<oml:class_name>Framework.custom_sklearn_pipeline.CustomPipelineModel</oml:class_name>\n\t\t\t<oml:external_version>Framework==0.0.1,openml==0.10.2,sklearn==0.20.1</oml:external_version>\n\t\t\t<oml:description></oml:description>\n\t\t\t<oml:language>English</oml:language>\n\t\t\t<oml:dependencies>sklearn==0.20.1\nnumpy&gt;=1.6.1\nscipy&gt;=0.9</oml:dependencies>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>ensemble_type</oml:name>\n\t\t\t\t<oml:default_value>\"XGBoost\"</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>explainer_type</oml:name>\n\t\t\t\t<oml:default_value>\"Linear\"</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>nClusters</oml:name>\n\t\t\t\t<oml:default_value>3</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:parameter>\n\t\t\t\t<oml:name>notebook_mode</oml:name>\n\t\t\t\t<oml:default_value>\"Shapley\"</oml:default_value>\n\t\t\t</oml:parameter>\n\t\t\t<oml:tag>openml-python</oml:tag>\n\t\t\t<oml:tag>sklearn</oml:tag>\n\t\t\t<oml:tag>scikit-learn</oml:tag>\n\t\t\t<oml:tag>python</oml:tag>\n\t\t\t<oml:tag>sklearn_0.20.1</oml:tag>\n\t\t</oml:flow>\n\t</oml:component>\n\t<oml:tag>openml-python</oml:tag>\n\t<oml:tag>sklearn</oml:tag>\n\t<oml:tag>scikit-learn</oml:tag>\n\t<oml:tag>python</oml:tag>\n\t<oml:tag>sklearn_0.20.1</oml:tag>\n</oml:flow>\nProblem validating uploaded description file - XML does not correspond to XSD schema. Error Element '{http://openml.org/openml}description': [facet 'minLength'] The value has a length of '0'; this underruns the allowed minimum length of '1'.\n on line 53 column 0. Error Element '{http://openml.org/openml}description': '' is not a valid value of the atomic type '{http://openml.org/openml}basic_latin1024'.\n on line 53 column 0."
     ]
    }
   ],
   "source": [
    "myrun = run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
